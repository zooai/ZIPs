# ZIP-002: Zoo PoAI (Proof of AI)

**Status**: Active  
**Type**: Consensus Specification  
**Created**: 2025-10-28  
**Authors**: Zoo Labs Foundation  
**Builds On**: [HIP-002 (ASO)](https://github.com/hanzoai/papers/blob/main/hips/HIP-002-aso.md), [ZIP-001 (DSO)](ZIP-001-dso.md)  
**Used By**: [HIP-004 (HMM)](https://github.com/hanzoai/papers/blob/main/hips/HIP-004-hmm.md) - Hanzo Network pricing layer

## Abstract

This ZIP specifies **Proof of AI (PoAI)**, Zoo Labs Foundation's consensus mechanism for verifiable AI compute and experiential learning. PoAI is a **Bayesian active inference-inspired, training-free, distributed GRPO, LLM-agnostic experiential layer** for building collective intelligence.

## Motivation

While Hanzo Network provides economic infrastructure (HMM pricing, L1 settlement), Zoo provides the **consensus and verification layer** that ensures AI work is authentic, high-quality, and contributes to collective intelligence.

PoAI enables:
1. **Verifiable Compute**: TEE attestations + Merkle proofs for AI inference/training
2. **Quality Scoring**: Bayesian active inference for experience quality
3. **Training-Free Learning**: Distributed GRPO across heterogeneous LLMs
4. **Collective Intelligence**: Experiential priors aggregated via DSO (ZIP-001)
5. **Economic Incentives**: Integrates with Hanzo's HMM (HIP-004) for rewards

## Specification

### Core Components

#### 1. Attestation Framework

**TEE-Based Attestations**:
```solidity
struct PoAIAttestation {
    bytes32 taskHash;           // Task specification
    bytes32 resultHash;         // Merkle root of outputs
    bytes teeReport;            // SGX/SEV attestation
    uint256 computeUnits;       // Normalized compute
    uint256 timestamp;
    address validator;
}
```

**Validation**:
- TEE remote attestation verification
- Merkle proof validation for outputs
- Replay protection (task + timestamp uniqueness)
- Slashing for fraudulent attestations

#### 2. Bayesian Active Inference

**Information Gain Metric**:
```
Î”I = H(prior) - H(posterior | experience)
```

Where:
- `H(Â·)` is Shannon entropy
- Prior: Agent's current belief state
- Posterior: Updated beliefs after experience
- **Goal**: Maximize information gain per experience

**Expected Free Energy (EFE)**:
```
EFE(Ï€) = E_q[Î”I] + E_q[Î”U] - Î»_c Â· E_q[cost]
```

Where:
- `Ï€`: Agent policy/strategy
- `Î”I`: Information gain (epistemic value)
- `Î”U`: Utility improvement (pragmatic value)
- `cost`: Compute resources consumed
- `Î»_c`: Cost coefficient (default: 0.1)

**Quality Scoring**:
```
q_i = Ïƒ(w_I Â· Î”I + w_U Â· Î”U - w_c Â· cost_i)
```

Where:
- `Ïƒ(Â·)`: Sigmoid function [0, 1]
- `w_I = 1.0`: Information weight
- `w_U = 0.5`: Utility weight
- `w_c = 0.1`: Cost weight

#### 3. Training-Free Distributed GRPO

**TF-GRPO Overview** (from Hanzo ASO):
- Bayesian product-of-experts (PoE) decoding
- Token/embedding-level experiential priors
- Zero-training adaptation across models

**Distributed Extension** (Zoo contribution):
```
# Each agent runs local TF-GRPO
A_i^(local) = (g_i - mean(g)) / (std(g) + Îµ)

# Aggregate via Byzantine-robust median (DSO)
A_consensus = weighted_median({A_i}, {stake_i Ã— q_i})

# Apply to any LLM via PoE decoding
P_aggregate(y | x) = Î _i P_i(y | x, A_i)^(w_i)
```

**Key Insight**: LLM-agnostic because priors are semantic (token/embedding level), not model-specific parameters.

#### 4. Experiential Layer for Collective Intelligence

**Experience Schema**:
```json
{
  "experience_id": "uuid",
  "agent_address": "0x...",
  "task_type": "coding|reasoning|...",
  "context": "problem description",
  "trajectory": [
    {"state": "...", "action": "...", "reward": 0.8}
  ],
  "outcome": "success|failure",
  "advantages": {
    "token_bins": [0.12, -0.05, ...],  // BitDelta compressed
    "embedding_centroids": [...],
  },
  "metadata": {
    "model": "gpt-4|claude|...",
    "cost": 0.05,
    "duration_sec": 12.3,
    "quality_score": 0.87
  }
}
```

**Collective Intelligence Flow**:
1. Agent completes task â†’ extracts advantages (ASO)
2. Submits to ExperienceRegistry (DSO) with PoAI attestation
3. Validators verify quality â†’ update reputation
4. High-quality experiences aggregated (Byzantine-robust)
5. Other agents fetch â†’ improve via PoE decoding
6. **Result**: System learns collectively without retraining

#### 5. Integration with Hanzo Network

**HMM Pricing** (Hanzo HIP-004):
- PoAI attestations determine compute quality `q_j`
- Quality-weighted supply in HMM: `Î¨_i^eff = Î£_j q_j Â· Î¨_ij`
- Higher quality â†’ better routing in marketplace

**Settlement**:
```
1. Client locks $AI in HMM escrow
2. Worker completes job â†’ submits PoAI attestation (Zoo)
3. Validators verify attestation â†’ update quality score
4. HMM releases payment (Hanzo) + PoAI bonus (Zoo)
5. If fraudulent: Slash bond, refund client
```

**Emissions** (shared between Hanzo/Zoo):
```
R_total = R_HMM (Hanzo) + R_PoAI (Zoo)

R_HMM = base compute rewards (via HMM pricing)
R_PoAI = Î³Â·Î”I + Î²Â·Î”U (quality bonus from Zoo)
```

### Implementation Path

**Phase 1 - Attestation Infrastructure** (Q4 2025):
- âœ… TEE attestation framework
- âœ… Merkle proof validation
- ðŸ”¨ Quality scoring via Bayesian active inference

**Phase 2 - Distributed GRPO** (Q1 2026):
- ðŸ”¨ TF-GRPO distribution across agents
- ðŸ”¨ LLM-agnostic prior application
- ðŸ”¨ Integration with DSO aggregation (ZIP-001)

**Phase 3 - Collective Intelligence** (Q2 2026):
- ðŸ”„ Experiential layer at scale (1000+ agents)
- ðŸ”„ Cross-domain transfer (code â†’ reasoning â†’ creative)
- ðŸ”„ Autonomous quality verification network

## Relationship to Hanzo Infrastructure

PoAI is Zoo's consensus layer that **integrates with** Hanzo's economic infrastructure:

1. **Hanzo Provides**:
   - HMM (HIP-004): Pricing and settlement for compute
   - Network: L1 blockchain for transactions
   - ASO (HIP-002): Single-agent TF-GRPO foundation

2. **Zoo Provides**:
   - PoAI (ZIP-002): Consensus and quality verification
   - DSO (ZIP-001): Multi-agent coordination
   - Collective intelligence layer

3. **Integration**:
   - PoAI attestations determine quality weights in HMM
   - HMM handles economic settlement, PoAI handles verification
   - Hanzo Network uses HMM for pricing, PoAI for consensus

## Co-Development History

**2024 Q1-Q2**: Hanzo develops ASO (HIP-002) with TF-GRPO foundation  
**2024 Q3**: Zoo extends with PoAI consensus and quality verification  
**2024 Q3**: Zoo develops DSO (ZIP-001) for multi-agent aggregation  
**2024 Q4**: Integration: Hanzo's HMM pricing + Zoo's PoAI consensus  
**2025 Q1**: Production deployment on Hanzo L1 with Zoo's verification layer  

This represents **years of co-development** between Hanzo AI Inc (economic layer) and Zoo Labs Foundation (consensus/intelligence layer).

## Performance Metrics

**Attestation Verification**:
- TEE validation: < 50ms per attestation
- Merkle proof verification: < 10ms per proof
- Quality scoring: < 100ms per experience

**Distributed GRPO**:
- Prior aggregation: ~1.8s for 100 agents (via DSO)
- LLM-agnostic application: no additional training required
- Improvement over isolated agents: 15.2% (from ZIP-001)

**Economic Integration**:
- PoAI bonus: up to 10% of base compute rewards
- Slashing rate: 50% of bond for fraudulent attestations
- Quality threshold: q â‰¥ 0.3 to avoid slashing

## Related Resources

- **Paper**: https://github.com/zooai/papers/blob/main/zoo-poai.pdf (TODO)
- **Dependencies**:
  - [HIP-002 (ASO)](https://github.com/hanzoai/papers/blob/main/hips/HIP-002-aso.md): TF-GRPO foundation
  - [ZIP-001 (DSO)](ZIP-001-dso.md): Multi-agent aggregation
  - [HIP-004 (HMM)](https://github.com/hanzoai/papers/blob/main/hips/HIP-004-hmm.md): Economic settlement

---

*ZIP-002 Created: October 28, 2025*  
*Status: Active*  
*Contact: foundation@zoo.ai*
